{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Veo3 Video Generation with AI-Enhanced Prompts\n",
        "\n",
        "This notebook demonstrates a streamlined workflow for generating videos using Google's Veo3 Fast API with AI-enhanced prompts. The workflow includes:\n",
        "\n",
        "1. **User Input**: Capture initial video prompt\n",
        "2. **Prompt Generation**: Generate multiple creative variations using `pydantic_ai_agents`\n",
        "3. **Prompt Enhancement**: Enhance prompts with technical details using `langraph_agents`\n",
        "4. **Prompt Selection**: Interactive selection from 3 enhanced prompts\n",
        "5. **Video Generation**: Generate video using Veo3 Fast API\n",
        "6. **Video Playback**: Display the generated video\n",
        "\n",
        "## Requirements\n",
        "\n",
        "- Google API Key (for Gemini and Veo3) - **Only requirement!**\n",
        "- Tavily API Key (optional, for enhanced search)\n",
        "\n",
        "## Streamlined Setup\n",
        "\n",
        "```bash\n",
        "# Install required packages\n",
        "pip install -e .\n",
        "\n",
        "# Set environment variable (only requirement)\n",
        "export GOOGLE_API_KEY=\"your-google-api-key\"\n",
        "\n",
        "# Optional for enhanced search\n",
        "export TAVILY_API_KEY=\"your-tavily-api-key\"\n",
        "```\n",
        "\n",
        "**Note**: This workflow no longer requires Google Cloud Project or Vertex AI setup!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Standard library imports\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import json\n",
        "import base64\n",
        "from typing import List, Dict, Any, Optional\n",
        "from pathlib import Path\n",
        "\n",
        "# Third-party imports\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, Video, Markdown, clear_output\n",
        "from tqdm.notebook import tqdm\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from dotenv import load_dotenv\n",
        "import nest_asyncio\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Apply nest_asyncio to handle nested event loops in Jupyter\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Add project root to path for importing local modules\n",
        "project_root = Path.cwd()\n",
        "if str(project_root) not in sys.path:\n",
        "    sys.path.insert(0, str(project_root))\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration and Environment Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîß Initializing streamlined Veo3 configuration...\n",
            "‚úÖ Configuration validated and client initialized\n",
            "üé¨ Veo3 Model: veo-2.0-generate-001\n",
            "üß† Gemini Model: gemini-2.5-flash\n",
            "‚è±Ô∏è Default Duration: 8s\n",
            "üìê Default Aspect Ratio: 16:9\n",
            "‚ÑπÔ∏è  Notes:\n",
            "   - Using streamlined configuration without Vertex AI dependencies\n"
          ]
        }
      ],
      "source": [
        "# Import the streamlined Veo3 configuration\n",
        "from veo3_config import get_veo3_config, get_client_manager, validate_veo3_setup\n",
        "\n",
        "# Initialize configuration following Get_started_Veo.ipynb pattern\n",
        "print(\"üîß Initializing streamlined Veo3 configuration...\")\n",
        "\n",
        "try:\n",
        "    # Get configuration instance\n",
        "    config = get_veo3_config()\n",
        "    \n",
        "    # Get client manager\n",
        "    client_manager = get_client_manager()\n",
        "    \n",
        "    # Initialize Google GenAI client (following Get_started_Veo.ipynb pattern)\n",
        "    client = client_manager.get_genai_client()\n",
        "    \n",
        "    # Validate setup\n",
        "    validation_results = validate_veo3_setup()\n",
        "    \n",
        "    if validation_results[\"config_valid\"]:\n",
        "        print(\"‚úÖ Configuration validated and client initialized\")\n",
        "        print(f\"üé¨ Veo3 Model: {config.VEO3_MODEL}\")\n",
        "        print(f\"üß† Gemini Model: {config.GEMINI_MODEL}\")\n",
        "        print(f\"‚è±Ô∏è Default Duration: {config.DEFAULT_DURATION_SECONDS}s\")\n",
        "        print(f\"üìê Default Aspect Ratio: {config.DEFAULT_ASPECT_RATIO}\")\n",
        "        \n",
        "        if validation_results.get(\"notes\"):\n",
        "            print(\"‚ÑπÔ∏è  Notes:\")\n",
        "            for note in validation_results[\"notes\"]:\n",
        "                print(f\"   - {note}\")\n",
        "    else:\n",
        "        print(\"‚ùå Configuration validation failed:\")\n",
        "        for error in validation_results[\"errors\"]:\n",
        "            print(f\"   - {error}\")\n",
        "        raise RuntimeError(\"Configuration validation failed\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Setup failed: {e}\")\n",
        "    print(\"\\nüìã Required environment variables:\")\n",
        "    print(\"   GOOGLE_API_KEY: Your Google API key from AI Studio\")\n",
        "    print(\"\\nüí° To fix this:\")\n",
        "    print(\"   1. Get an API key from https://aistudio.google.com/app/apikey\")\n",
        "    print(\"   2. Set: export GOOGLE_API_KEY='your-api-key-here'\")\n",
        "    print(\"   3. Restart the notebook after setting the environment variable\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Import Local Agent Modules\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Pydantic AI agents imported successfully\n",
            "‚úÖ LangGraph agents imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import pydantic_ai_agents for initial prompt generation\n",
        "try:\n",
        "    from pydantic_ai_agents import agents as pydantic_agents\n",
        "    from pydantic_ai_agents.schemas import IdeaList, VideoPromptIdea\n",
        "    print(\"‚úÖ Pydantic AI agents imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import pydantic_ai_agents: {e}\")\n",
        "    print(\"Please ensure you're running this notebook from the project root directory\")\n",
        "\n",
        "# Import langraph_agents for prompt enhancement\n",
        "try:\n",
        "    from langraph_agents.prompt_enhancer_graph import PromptEnhancerWorkflow\n",
        "    from langraph_agents.prompt_enhancer_state import WorkflowOutputState\n",
        "    print(\"‚úÖ LangGraph agents imported successfully\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import langraph_agents: {e}\")\n",
        "    print(\"Please ensure you're running this notebook from the project root directory\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Video Generation Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Video generation helper functions ready\n",
            "üé¨ Using model: veo-2.0-generate-001\n",
            "‚öôÔ∏è Video defaults: 8s, 16:9\n"
          ]
        }
      ],
      "source": [
        "class VideoGenerator:\n",
        "    \"\"\"\n",
        "    Handles video generation using Veo3 Fast API.\n",
        "    \n",
        "    Following the exact pattern from Get_started_Veo.ipynb for video generation\n",
        "    with proper configuration management and error handling.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, client, client_manager):\n",
        "        self.client = client\n",
        "        self.client_manager = client_manager\n",
        "        self.config = client_manager.config\n",
        "        self.current_operation = None\n",
        "    \n",
        "    def generate_video(\n",
        "        self, \n",
        "        prompt: str,\n",
        "        duration_seconds: int = None,\n",
        "        aspect_ratio: str = None,\n",
        "        enhance_prompt: bool = True,\n",
        "        resolution: str = \"1080p\",\n",
        "        progress_callback=None\n",
        "    ) -> Dict[str, Any]:\n",
        "        \"\"\"Generate video using Veo3 Fast API\"\"\"\n",
        "        \n",
        "        # Use defaults if not specified\n",
        "        duration_seconds = duration_seconds or self.config.DEFAULT_DURATION_SECONDS\n",
        "        aspect_ratio = aspect_ratio or self.config.DEFAULT_ASPECT_RATIO\n",
        "        \n",
        "        try:\n",
        "            if progress_callback:\n",
        "                progress_callback(\"üöÄ Starting video generation...\")\n",
        "            \n",
        "            # Generate video using Veo3 Fast API (following Get_started_Veo.ipynb pattern)\n",
        "            video_config = self.client_manager.get_video_generation_config(\n",
        "                duration_seconds=duration_seconds,\n",
        "                aspect_ratio=aspect_ratio,\n",
        "                # resolution=resolution,\n",
        "                # enhance_prompt=enhance_prompt\n",
        "            )\n",
        "            \n",
        "            operation = self.client.models.generate_videos(\n",
        "                model=self.config.VEO3_MODEL,\n",
        "                prompt=prompt,\n",
        "                config=video_config,\n",
        "            )\n",
        "            \n",
        "            self.current_operation = operation\n",
        "            \n",
        "            if progress_callback:\n",
        "                progress_callback(f\"‚è≥ Video generation started. Operation ID: {operation.name}\")\n",
        "            \n",
        "            # Poll for completion\n",
        "            start_time = time.time()\n",
        "            while not operation.done:\n",
        "                time.sleep(10)\n",
        "                operation = self.client.operations.get(operation)\n",
        "                \n",
        "                elapsed_time = time.time() - start_time\n",
        "                if progress_callback:\n",
        "                    progress_callback(\n",
        "                        f\"‚è≥ Generating video... Elapsed time: {elapsed_time:.0f}s\"\n",
        "                    )\n",
        "                \n",
        "                # Timeout after 10 minutes\n",
        "                if elapsed_time > 600:\n",
        "                    raise TimeoutError(\"Video generation timed out after 10 minutes\")\n",
        "\n",
        "            # Correctly handle the final operation result\n",
        "            if operation.response:\n",
        "                video_data = operation.result.generated_videos[0]\n",
        "                video_bytes = None\n",
        "\n",
        "                # Per official Gemini examples, we must first download the file to make it available locally.\n",
        "                try:\n",
        "                    if progress_callback:\n",
        "                        progress_callback(\"‚¨áÔ∏è Caching video file locally...\")\n",
        "                    \n",
        "                    # This call populates the video object with data that can be saved.\n",
        "                    self.client.files.download(file=video_data.video)\n",
        "                    \n",
        "                    # Now that it's cached, we can save it to get the bytes.\n",
        "                    tmp_filename = f\"generated_video_{int(time.time())}.mp4\"\n",
        "                    video_data.video.save(tmp_filename)\n",
        "                    with open(tmp_filename, \"rb\") as f:\n",
        "                        video_bytes = f.read()\n",
        "                    os.remove(tmp_filename) # Clean up the temporary file\n",
        "                    \n",
        "                    if progress_callback:\n",
        "                        progress_callback(\"‚úÖ Video file cached successfully.\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    if progress_callback:\n",
        "                        progress_callback(f\"‚ö†Ô∏è Download/save method failed: {e}. Trying fallback.\")\n",
        "                    \n",
        "                    # Fallback to accessing inline bytes if the primary method fails\n",
        "                    try:\n",
        "                        video_bytes = getattr(video_data.video, 'video_bytes', None)\n",
        "                    except Exception:\n",
        "                        video_bytes = None\n",
        "\n",
        "                # Final check\n",
        "                if video_bytes is None:\n",
        "                    raise RuntimeError(\"Video generation completed, but failed to retrieve video bytes using any available method.\")\n",
        "\n",
        "                result = {\n",
        "                    \"success\": True,\n",
        "                    \"video_bytes\": video_bytes,\n",
        "                    \"operation_id\": operation.name,\n",
        "                    \"prompt_used\": prompt,\n",
        "                    \"generation_time\": time.time() - start_time,\n",
        "                    \"config\": {\n",
        "                        \"duration_seconds\": duration_seconds,\n",
        "                        \"aspect_ratio\": aspect_ratio,\n",
        "                    }\n",
        "                }\n",
        "                \n",
        "                if progress_callback:\n",
        "                    progress_callback(f\"‚úÖ Video generated successfully in {result['generation_time']:.1f}s\")\n",
        "                \n",
        "                return result\n",
        "            else:\n",
        "                error_message = \"Video generation failed\"\n",
        "                if hasattr(operation, 'error') and operation.error:\n",
        "                    error_message += f\": {operation.error.message}\"\n",
        "                raise RuntimeError(error_message)\n",
        "                \n",
        "        except Exception as e:\n",
        "            if progress_callback:\n",
        "                progress_callback(f\"‚ùå Error: {str(e)}\")\n",
        "            return {\n",
        "                \"success\": False,\n",
        "                \"error\": str(e),\n",
        "                \"prompt_used\": prompt\n",
        "            }\n",
        "    \n",
        "    def save_video(self, video_bytes: bytes, filename: str = None) -> str:\n",
        "        \"\"\"Save video bytes to file\"\"\"\n",
        "        if video_bytes is None:\n",
        "            raise ValueError(\"No video data to save. The video generation process returned None.\")\n",
        "        \n",
        "        if filename is None:\n",
        "            timestamp = int(time.time())\n",
        "            filename = f\"generated_video_{timestamp}.mp4\"\n",
        "        \n",
        "        with open(filename, \"wb\") as f:\n",
        "            f.write(video_bytes)\n",
        "        \n",
        "        return filename\n",
        "    \n",
        "    def display_video(self, video_bytes: bytes, width: int = 720) -> None:\n",
        "        \"\"\"Display video in Jupyter notebook\"\"\"\n",
        "        filename = self.save_video(video_bytes)\n",
        "        display(Video(filename, embed=True, width=width))\n",
        "        return filename\n",
        "\n",
        "# Initialize video generator\n",
        "video_generator = VideoGenerator(client, client_manager)\n",
        "\n",
        "print(\"‚úÖ Video generation helper functions ready\")\n",
        "print(f\"üé¨ Using model: {config.VEO3_MODEL}\")\n",
        "print(f\"‚öôÔ∏è Video defaults: {config.DEFAULT_DURATION_SECONDS}s, {config.DEFAULT_ASPECT_RATIO}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Prompt Processing Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:langraph_agents.prompt_enhancer_graph:Building prompt enhancer graph...\n",
            "INFO:langraph_agents.prompt_enhancer_graph:Prompt enhancer graph compiled successfully\n",
            "INFO:langraph_agents.prompt_enhancer_graph:PromptEnhancerWorkflow initialized successfully\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Prompt enhancement workflow initialized\n",
            "‚úÖ Prompt processing pipeline ready\n"
          ]
        }
      ],
      "source": [
        "class PromptProcessingPipeline:\n",
        "    \"\"\"Orchestrates the prompt generation and enhancement pipeline\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.pydantic_agents = pydantic_agents\n",
        "        self.enhancement_workflow = None\n",
        "        \n",
        "        # Initialize LangGraph workflow\n",
        "        try:\n",
        "            self.enhancement_workflow = PromptEnhancerWorkflow()\n",
        "            print(\"‚úÖ Prompt enhancement workflow initialized\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Warning: Could not initialize enhancement workflow: {e}\")\n",
        "    \n",
        "    def generate_initial_ideas(self, user_prompt: str, num_ideas: int = 3) -> List[VideoPromptIdea]:\n",
        "        \"\"\"Generate initial video prompt ideas using pydantic_ai_agents\"\"\"\n",
        "        try:\n",
        "            # Use topic variations for more diverse prompts\n",
        "            result = self.pydantic_agents.generate_variations_for_topic(\n",
        "                topic=user_prompt, \n",
        "                num_ideas=num_ideas\n",
        "            )\n",
        "            return result.ideas\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error generating initial ideas: {e}\")\n",
        "            # Fallback: create basic variations manually\n",
        "            return self._create_fallback_ideas(user_prompt, num_ideas)\n",
        "    \n",
        "    def _create_fallback_ideas(self, user_prompt: str, num_ideas: int) -> List[VideoPromptIdea]:\n",
        "        \"\"\"Create fallback ideas if pydantic agents fail\"\"\"\n",
        "        variations = [\n",
        "            f\"Cinematic version: {user_prompt} with dramatic lighting and smooth camera movements\",\n",
        "            f\"Artistic interpretation: {user_prompt} in a stylized, visually striking manner\",\n",
        "            f\"Dynamic perspective: {user_prompt} with engaging visual effects and motion\"\n",
        "        ]\n",
        "        \n",
        "        return [\n",
        "            VideoPromptIdea(\n",
        "                title=f\"Variation {i+1}\",\n",
        "                description=variations[i % len(variations)],\n",
        "                sources=[]\n",
        "            )\n",
        "            for i in range(min(num_ideas, len(variations)))\n",
        "        ]\n",
        "    \n",
        "    def enhance_prompt(self, prompt_description: str) -> Dict[str, Any]:\n",
        "        \"\"\"Enhance a prompt using langraph_agents\"\"\"\n",
        "        if not self.enhancement_workflow:\n",
        "            # Fallback enhancement\n",
        "            return self._create_fallback_enhancement(prompt_description)\n",
        "        \n",
        "        try:\n",
        "            result = self.enhancement_workflow.enhance_prompt(prompt_description)\n",
        "            return {\n",
        "                \"enhanced_prompt\": result[\"natural_language_prompt\"],\n",
        "                \"technical_details\": result[\"json_prompt\"],\n",
        "                \"quality_score\": result[\"quality_score\"],\n",
        "                \"enhancement_notes\": result[\"enhancement_notes\"],\n",
        "                \"original\": prompt_description\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Warning: Enhancement failed, using fallback: {e}\")\n",
        "            return self._create_fallback_enhancement(prompt_description)\n",
        "    \n",
        "    def _create_fallback_enhancement(self, prompt_description: str) -> Dict[str, Any]:\n",
        "        \"\"\"Create fallback enhancement if langraph fails\"\"\"\n",
        "        enhanced = f\"{prompt_description}. Shot in high quality with professional cinematography, proper lighting, and smooth camera movement. 8 seconds duration, 16:9 aspect ratio.\"\n",
        "        \n",
        "        return {\n",
        "            \"enhanced_prompt\": enhanced,\n",
        "            \"technical_details\": {\n",
        "                \"duration_seconds\": 8,\n",
        "                \"aspect_ratio\": \"16:9\",\n",
        "                \"style\": \"professional\",\n",
        "                \"quality\": \"high\"\n",
        "            },\n",
        "            \"quality_score\": 0.7,\n",
        "            \"enhancement_notes\": [\"Used fallback enhancement\"],\n",
        "            \"original\": prompt_description\n",
        "        }\n",
        "    \n",
        "    def process_user_prompt(self, user_prompt: str) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Complete pipeline: generate ideas and enhance them\"\"\"\n",
        "        print(f\"üé¨ Processing user prompt: {user_prompt}\")\n",
        "        \n",
        "        # Step 1: Generate initial ideas\n",
        "        print(\"üìù Generating initial prompt variations...\")\n",
        "        ideas = self.generate_initial_ideas(user_prompt, num_ideas=1)\n",
        "        \n",
        "        # Step 2: Enhance each idea\n",
        "        enhanced_prompts = []\n",
        "        for i, idea in enumerate(ideas, 1):\n",
        "            print(f\"‚ö° Enhancing prompt {i}/3...\")\n",
        "            enhancement = self.enhance_prompt(idea.description)\n",
        "            enhancement[\"original_title\"] = idea.title\n",
        "            enhancement[\"idea_index\"] = i\n",
        "            enhanced_prompts.append(enhancement)\n",
        "        \n",
        "        print(\"‚úÖ Prompt processing complete!\")\n",
        "        return enhanced_prompts\n",
        "\n",
        "# Initialize the pipeline\n",
        "pipeline = PromptProcessingPipeline()\n",
        "\n",
        "print(\"‚úÖ Prompt processing pipeline ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Interactive Workflow Interface\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Interactive workflow ready\n"
          ]
        }
      ],
      "source": [
        "class VideoGenerationWorkflow:\n",
        "    \"\"\"Complete interactive workflow for video generation\"\"\"\n",
        "    \n",
        "    def __init__(self, pipeline, video_generator):\n",
        "        self.pipeline = pipeline\n",
        "        self.video_generator = video_generator\n",
        "        self.enhanced_prompts = []\n",
        "        self.selected_prompt = None\n",
        "        self.generated_video = None\n",
        "        \n",
        "        # UI components\n",
        "        self.setup_ui()\n",
        "    \n",
        "    def setup_ui(self):\n",
        "        \"\"\"Setup the user interface components\"\"\"\n",
        "        # Input section\n",
        "        self.prompt_input = widgets.Textarea(\n",
        "            value=\"A cat playing with a ball of yarn in a sunlit room\",\n",
        "            placeholder=\"Enter your video prompt here...\",\n",
        "            description=\"Video Prompt:\",\n",
        "            layout=widgets.Layout(width=\"100%\", height=\"80px\")\n",
        "        )\n",
        "        \n",
        "        self.generate_prompts_btn = widgets.Button(\n",
        "            description=\"üé≠ Generate Enhanced Prompts\",\n",
        "            button_style=\"primary\",\n",
        "            layout=widgets.Layout(width=\"250px\")\n",
        "        )\n",
        "        self.generate_prompts_btn.on_click(self.on_generate_prompts_click)\n",
        "        \n",
        "        # Prompt selection section (increase height to avoid cramped layout)\n",
        "        self.prompt_selector = widgets.RadioButtons(\n",
        "            options=[],\n",
        "            description=\"Select Prompt:\",\n",
        "            disabled=True,\n",
        "            layout=widgets.Layout(width=\"100%\", height=\"220px\", overflow_y=\"auto\")\n",
        "        )\n",
        "        \n",
        "        self.generate_video_btn = widgets.Button(\n",
        "            description=\"üé¨ Generate Video\",\n",
        "            button_style=\"success\",\n",
        "            disabled=True,\n",
        "            layout=widgets.Layout(width=\"200px\")\n",
        "        )\n",
        "        self.generate_video_btn.on_click(self.on_generate_video_click)\n",
        "        \n",
        "        # Video settings\n",
        "        self.duration_slider = widgets.IntSlider(\n",
        "            value=8,\n",
        "            min=4,\n",
        "            max=12,\n",
        "            description=\"Duration (s):\",\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "        \n",
        "        self.aspect_ratio_dropdown = widgets.Dropdown(\n",
        "            options=[\"16:9\", \"9:16\", \"1:1\"],\n",
        "            value=\"16:9\",\n",
        "            description=\"Aspect Ratio:\",\n",
        "            style={'description_width': 'initial'}\n",
        "        )\n",
        "        \n",
        "        \n",
        "        # Output section\n",
        "        self.output_area = widgets.Output()\n",
        "        self.progress_area = widgets.Output()\n",
        "    \n",
        "    def display_interface(self):\n",
        "        \"\"\"Display the complete interface\"\"\"\n",
        "        display(HTML(\"<h2>üé¨ AI-Enhanced Video Generation Workflow</h2>\"))\n",
        "        \n",
        "        # Input section\n",
        "        display(HTML(\"<h3>1. Enter Your Prompt</h3>\"))\n",
        "        display(self.prompt_input)\n",
        "        display(self.generate_prompts_btn)\n",
        "        \n",
        "        # Progress area\n",
        "        display(self.progress_area)\n",
        "        \n",
        "        # Selection section\n",
        "        display(HTML(\"<h3>2. Select Enhanced Prompt</h3>\"))\n",
        "        display(self.prompt_selector)\n",
        "        \n",
        "        # Video settings\n",
        "        display(HTML(\"<h3>3. Video Settings</h3>\"))\n",
        "        settings_box = widgets.HBox([\n",
        "            self.duration_slider,\n",
        "            self.aspect_ratio_dropdown\n",
        "        ])\n",
        "        display(settings_box)\n",
        "        \n",
        "        # Generate button\n",
        "        display(self.generate_video_btn)\n",
        "        \n",
        "        # Output area\n",
        "        display(HTML(\"<h3>4. Generated Video</h3>\"))\n",
        "        display(self.output_area)\n",
        "    \n",
        "    def on_generate_prompts_click(self, button):\n",
        "        \"\"\"Handle prompt generation button click with observable progress using tqdm\"\"\"\n",
        "        user_prompt = self.prompt_input.value.strip()\n",
        "        if not user_prompt:\n",
        "            with self.progress_area:\n",
        "                clear_output(wait=True)\n",
        "                print(\"‚ùå Please enter a prompt first\")\n",
        "            return\n",
        "\n",
        "        # Start visible progress in the progress_area\n",
        "        with self.progress_area:\n",
        "            clear_output(wait=True)\n",
        "            print(\"üöÄ Starting prompt generation...\")\n",
        "\n",
        "            try:\n",
        "                # Step 1: Generate initial ideas and show progress\n",
        "                print(\"üìù Generating initial prompt variations...\")\n",
        "                ideas = self.pipeline.generate_initial_ideas(user_prompt, num_ideas=1)\n",
        "                print(f\"üìù Generated {len(ideas)} initial ideas.\")\n",
        "\n",
        "                # Step 2: Enhance each idea with a notebook progress bar\n",
        "                enhanced_prompts = []\n",
        "                progress_bar = tqdm(total=len(ideas), desc=\"Enhancing prompts\", unit=\"prompt\")\n",
        "                display(progress_bar)\n",
        "\n",
        "                for i, idea in enumerate(ideas, 1):\n",
        "                    progress_bar.set_description(f\"Enhancing {i}/{len(ideas)}: {idea.title}\")\n",
        "                    # Perform enhancement and capture any step-level errors\n",
        "                    try:\n",
        "                        enhancement = self.pipeline.enhance_prompt(idea.description)\n",
        "                    except Exception as inner_e:\n",
        "                        enhancement = self.pipeline._create_fallback_enhancement(idea.description)\n",
        "                        enhancement[\"enhancement_notes\"] = enhancement.get(\"enhancement_notes\", []) + [f\"Enhancement error: {inner_e}\"]\n",
        "\n",
        "                    enhancement[\"original_title\"] = idea.title\n",
        "                    enhancement[\"idea_index\"] = i\n",
        "                    enhanced_prompts.append(enhancement)\n",
        "                    progress_bar.update(1)\n",
        "\n",
        "                progress_bar.close()\n",
        "\n",
        "                # Update internal state and UI\n",
        "                self.enhanced_prompts = enhanced_prompts\n",
        "                options = []\n",
        "                for i, prompt_data in enumerate(self.enhanced_prompts):\n",
        "                    title = prompt_data.get(\"original_title\", f\"Option {i+1}\")\n",
        "                    preview = prompt_data[\"enhanced_prompt\"][:100] + \"...\"\n",
        "                    options.append((f\"{title}: {preview}\", i))\n",
        "\n",
        "                self.prompt_selector.options = options\n",
        "                self.prompt_selector.disabled = False\n",
        "                self.generate_video_btn.disabled = False\n",
        "\n",
        "                # Finalize progress output with details\n",
        "                clear_output(wait=True)\n",
        "                print(\"‚úÖ Enhanced prompts generated successfully!\")\n",
        "                print(\"üìã Please select one of the enhanced prompts below.\")\n",
        "                for i, prompt_data in enumerate(self.enhanced_prompts, 1):\n",
        "                    print(f\"\\n{'='*50}\")\n",
        "                    print(f\"üìù PROMPT {i}: {prompt_data.get('original_title', f'Option {i}')}\")\n",
        "                    print(f\"{'='*50}\")\n",
        "                    print(f\"Enhanced: {prompt_data['enhanced_prompt'][:200]}...\")\n",
        "                    print(f\"Quality Score: {prompt_data['quality_score']:.2f}\")\n",
        "                    if prompt_data.get('enhancement_notes'):\n",
        "                        print(f\"Notes: {', '.join(prompt_data['enhancement_notes'][:2])}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                clear_output(wait=True)\n",
        "                print(f\"‚ùå Error generating prompts: {e}\")\n",
        "    \n",
        "    def on_generate_video_click(self, button):\n",
        "        \"\"\"Handle video generation button click\"\"\"\n",
        "        if self.prompt_selector.value is None:\n",
        "            with self.progress_area:\n",
        "                clear_output(wait=True)\n",
        "                print(\"‚ùå Please select a prompt first\")\n",
        "            return\n",
        "        \n",
        "        # Get selected prompt\n",
        "        selected_index = self.prompt_selector.value\n",
        "        self.selected_prompt = self.enhanced_prompts[selected_index]\n",
        "        \n",
        "        with self.output_area:\n",
        "            clear_output(wait=True)\n",
        "            print(\"üé¨ Starting video generation...\")\n",
        "        \n",
        "        # Progress callback\n",
        "        def progress_callback(message):\n",
        "            with self.output_area:\n",
        "                print(message)\n",
        "        \n",
        "        # Generate video\n",
        "        try:\n",
        "            result = self.video_generator.generate_video(\n",
        "                prompt=self.selected_prompt[\"enhanced_prompt\"],\n",
        "                duration_seconds=self.duration_slider.value,\n",
        "                aspect_ratio=self.aspect_ratio_dropdown.value,\n",
        "                # resolution=\"1080p\",\n",
        "                progress_callback=progress_callback\n",
        "            )\n",
        "            \n",
        "            if result[\"success\"]:\n",
        "                with self.output_area:\n",
        "                    print(\"\\n\" + \"=\"*60)\n",
        "                    print(\"üéâ VIDEO GENERATION SUCCESSFUL!\")\n",
        "                    print(\"=\"*60)\n",
        "                    print(f\"‚è±Ô∏è Generation Time: {result['generation_time']:.1f} seconds\")\n",
        "                    print(f\"üìù Prompt Used: {result['prompt_used'][:100]}...\")\n",
        "                    print(f\"‚öôÔ∏è Settings: {result['config']}\")\n",
        "                    print(\"\\nüé¨ Playing video:\")\n",
        "                    \n",
        "                    # Display video\n",
        "                    filename = self.video_generator.display_video(result[\"video_bytes\"])\n",
        "                    print(f\"\\nüíæ Video saved as: {filename}\")\n",
        "                    \n",
        "                self.generated_video = result\n",
        "            else:\n",
        "                with self.output_area:\n",
        "                    print(f\"‚ùå Video generation failed: {result['error']}\")\n",
        "        \n",
        "        except Exception as e:\n",
        "            with self.output_area:\n",
        "                print(f\"‚ùå Unexpected error: {e}\")\n",
        "\n",
        "# Initialize the workflow\n",
        "workflow = VideoGenerationWorkflow(pipeline, video_generator)\n",
        "\n",
        "print(\"‚úÖ Interactive workflow ready\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Launch the Interactive Workflow\n",
        "\n",
        "Run the cell below to start the interactive video generation workflow. The interface includes:\n",
        "\n",
        "1. **Prompt Input**: Enter your initial video idea\n",
        "2. **AI Enhancement**: Generate 3 enhanced versions using both agent systems\n",
        "3. **Prompt Selection**: Choose your preferred enhanced prompt\n",
        "4. **Video Settings**: Customize duration, aspect ratio, and resolution\n",
        "5. **Video Generation**: Generate and display the final video\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h2>üé¨ AI-Enhanced Video Generation Workflow</h2>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>1. Enter Your Prompt</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f64a56b31c1648709d6f78ab012bab2e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Textarea(value='A cat playing with a ball of yarn in a sunlit room', description='Video Prompt:', layout=Layou‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a6d41e99c2a49b9b8bf193db8c93085",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(button_style='primary', description='üé≠ Generate Enhanced Prompts', layout=Layout(width='250px'), style=‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2f6908db6974214b1b24153196a09c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>2. Select Enhanced Prompt</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6a301b0ec0df4ebb992332ad0da51331",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "RadioButtons(description='Select Prompt:', disabled=True, layout=Layout(height='220px', width='100%'), options‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>3. Video Settings</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "432174f246a9433f9ca3dbcdf56d563b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntSlider(value=8, description='Duration (s):', max=12, min=4, style=SliderStyle(description_wi‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd3ddebdcffa4c0faf97a19ff09c4db8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Button(button_style='success', description='üé¨ Generate Video', disabled=True, layout=Layout(width='200px'), st‚Ä¶"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>4. Generated Video</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c7453815abb4b4cbb9f05ea28923034",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Launch the interactive workflow\n",
        "workflow.display_interface()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Advanced Usage Examples\n",
        "\n",
        "For advanced users, you can also use the components directly:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Direct usage of the pipeline\n",
        "def demo_direct_usage():\n",
        "    \"\"\"Demonstrate direct usage of the pipeline components\"\"\"\n",
        "    \n",
        "    print(\"üîß Direct Pipeline Usage Demo\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    # 1. Generate ideas directly\n",
        "    user_prompt = \"A magical forest with glowing mushrooms\"\n",
        "    print(f\"üìù User prompt: {user_prompt}\")\n",
        "    \n",
        "    # Generate ideas using pydantic agents\n",
        "    ideas = pipeline.generate_initial_ideas(user_prompt, num_ideas=2)\n",
        "    print(f\"\\nüí° Generated {len(ideas)} ideas:\")\n",
        "    for i, idea in enumerate(ideas, 1):\n",
        "        print(f\"  {i}. {idea.title}: {idea.description[:80]}...\")\n",
        "    \n",
        "    # 2. Enhance a specific idea\n",
        "    selected_idea = ideas[0]\n",
        "    print(f\"\\n‚ö° Enhancing idea: {selected_idea.title}\")\n",
        "    \n",
        "    enhancement = pipeline.enhance_prompt(selected_idea.description)\n",
        "    print(f\"\\n‚ú® Enhanced prompt:\")\n",
        "    print(f\"  Quality Score: {enhancement['quality_score']:.2f}\")\n",
        "    print(f\"  Enhanced: {enhancement['enhanced_prompt'][:150]}...\")\n",
        "    \n",
        "    # 3. Generate video directly\n",
        "    print(f\"\\nüé¨ Generating video...\")\n",
        "    \n",
        "    def simple_progress(msg):\n",
        "        print(f\"  {msg}\")\n",
        "    \n",
        "    result = video_generator.generate_video(\n",
        "        prompt=enhancement['enhanced_prompt'],\n",
        "        duration_seconds=6,\n",
        "        aspect_ratio=\"16:9\",\n",
        "        progress_callback=simple_progress\n",
        "    )\n",
        "    \n",
        "    if result[\"success\"]:\n",
        "        print(f\"\\n‚úÖ Success! Generated in {result['generation_time']:.1f}s\")\n",
        "        filename = video_generator.display_video(result[\"video_bytes\"], width=600)\n",
        "        print(f\"üíæ Saved as: {filename}\")\n",
        "    else:\n",
        "        print(f\"‚ùå Failed: {result['error']}\")\n",
        "\n",
        "# Uncomment to run the demo\n",
        "# demo_direct_usage()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This notebook provides a complete workflow for AI-enhanced video generation using:\n",
        "\n",
        "1. **Pydantic AI Agents** - Generate creative prompt variations\n",
        "2. **LangGraph Agents** - Enhance prompts with technical details\n",
        "3. **Veo3 Fast API** - Generate high-quality videos\n",
        "4. **Interactive Interface** - User-friendly workflow\n",
        "\n",
        "The system combines the creativity of AI agents with the power of Google's latest video generation technology to create professional-quality videos from simple text prompts.\n",
        "\n",
        "### Next Steps:\n",
        "\n",
        "- Experiment with different prompt styles\n",
        "- Try batch processing for multiple videos\n",
        "- Integrate with your own applications\n",
        "- Customize the enhancement pipeline\n",
        "\n",
        "Happy video generating! üé¨‚ú®\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
